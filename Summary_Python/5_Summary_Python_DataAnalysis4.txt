(1) Hierarchical indexing is an important feature of pandas that enables you to have multiple (two or more) index levels on an axis.

import pandas as pd
import numpy as np
data=pd.Series(np.random.randn(9),index=[['a','a','a','b','b','b','c','c','c'],[1,2,3,4,5,6,7,8,9]])
print(data)
print(data.index)

--

a  1   -1.252473
   2    0.112670
   3    1.124584
b  4   -0.778834
   5   -0.805543
   6    0.110976
c  7   -0.549029
   8   -1.110112
   9   -1.454899
dtype: float64
MultiIndex([('a', 1),
            ('a', 2),
            ('a', 3),
            ('b', 4),
            ('b', 5),
            ('b', 6),
            ('c', 7),
            ('c', 8),
            ('c', 9)],
           )


(2)

print(data['b':'c'])
print(data.loc[['b','c']])
print(data.loc[:,[2,5]])

--

b  4   -0.778834
   5   -0.805543
   6    0.110976
c  7   -0.549029
   8   -1.110112
   9   -1.454899
dtype: float64
b  4   -0.778834
   5   -0.805543
   6    0.110976
c  7   -0.549029
   8   -1.110112
   9   -1.454899
dtype: float64
a  2    0.112670
b  5   -0.805543
dtype: float64

(3)

Hierarchical indexing plays an important role in reshaping data and group-based operations like forming a pivot table. 
For example, you could rearrange the data into a DataFrame using its unstack method:

print(data.unstack())

--

          1        2         3         4         5         6         7  \
a -1.252473  0.11267  1.124584       NaN       NaN       NaN       NaN   
b       NaN      NaN       NaN -0.778834 -0.805543  0.110976       NaN   
c       NaN      NaN       NaN       NaN       NaN       NaN -0.549029   

          8         9  
a       NaN       NaN  
b       NaN       NaN  
c -1.110112 -1.454899 

(4)

The inverse operation of unstack is stack

print(data.unstack().stack())

--

a  1   -1.252473
   2    0.112670
   3    1.124584
b  4   -0.778834
   5   -0.805543
   6    0.110976
c  7   -0.549029
   8   -1.110112
   9   -1.454899
dtype: float64

(5)

With a DataFrame, either axis can have a hierarchical index:

df=pd.DataFrame(np.arange(12).reshape(4,3),index=[['a','b','c','d'],[1,1,2,2]],columns=[['ankit','kiio','summi'],['ankit','kiio','kiio']])
print(df)

--

    ankit kiio summi
    ankit kiio  kiio
a 1     0    1     2
b 1     3    4     5
c 2     6    7     8
d 2     9   10    11

(6)

df.index.names=['key1','key2']
df.columns.names=['column1','column2']
print(df)

--

column1   ankit kiio summi
column2   ankit kiio  kiio
key1 key2                 
a    1        0    1     2
b    1        3    4     5
c    2        6    7     8
d    2        9   10    11

(7)

A MultiIndex can be created by itself and then reused; the columns in the preceding DataFrame with level names could be created like this:

print(pd.MultiIndex.from_arrays([['ankit','kiio','summi'],['kiio','kiio','summi']],names=['column1','column2']))

--

MultiIndex([('ankit',  'kiio'),
            ( 'kiio',  'kiio'),
            ('summi', 'summi')],
           names=['column1', 'column2'])

(8)

print(df.swaplevel('key2','key1'))

--

column1   ankit kiio summi
column2   ankit kiio  kiio
key2 key1                 
1    a        0    1     2
     b        3    4     5
2    c        6    7     8
     d        9   10    11


(9)

sort_index, on the other hand, sorts the data using only the values in a single level. 
When swapping levels, it’s not uncommon to also use sort_index so that the result is lexicographically sorted by the indicated level:

print(df.sort_index(level=1))

--

column1   ankit kiio summi
column2   ankit kiio  kiio
key1 key2                 
a    1        0    1     2
b    1        3    4     5
c    2        6    7     8
d    2        9   10    11

(10)

Data selection performance is much better on hierarchically indexed objects if the index is lexicographically sorted starting with the outermost level—that is, 
the result of calling sort_index(level=0) or sort_index().

print(df.swaplevel(0, 1).sort_index(level=0))

--

column1   ankit kiio summi
column2   ankit kiio  kiio
key2 key1                 
1    a        0    1     2
     b        3    4     5
2    c        6    7     8
     d        9   10    11

(11)

print(df.sum(level='key2'))

--

column1 ankit kiio summi
column2 ankit kiio  kiio
key2                    
1           3    5     7
2          15   17    19

(12)

frame = pd.DataFrame({'a': range(7), 'b': range(7, 0, -1),'c': ['one', 'one', 'one', 'two', 'two','two', 'two'],'d': [0, 1, 2, 0, 1, 2, 3]})
frame2 = frame.set_index(['c', 'd'],drop=False)
print(frame2)

--

       a  b    c  d
c   d              
one 0  0  7  one  0
    1  1  6  one  1
    2  2  5  one  2
two 0  3  4  two  0
    1  4  3  two  1
    2  5  2  two  2
    3  6  1  two  3

(13)

reset_index, on the other hand, does the opposite of set_index; the hierarchical index levels are moved into the columns:

frame2 = frame.set_index(['c', 'd'])
print(frame2.reset_index())

--

     c  d  a  b
0  one  0  0  7
1  one  1  1  6
2  one  2  2  5
3  two  0  3  4
4  two  1  4  3
5  two  2  5  2
6  two  3  6  1

(14)

• pandas.merge connects rows in DataFrames based on one or more keys. This will be familiar to users of SQL or other relational databases, 
as it implements database join operations.

• pandas.concat concatenates or “stacks” together objects along an axis.

• The combine_first instance method enables splicing together overlapping data to fill in missing values in one object with values from another.

  key      name
0   a     ankit
1   b      kiio
2   c     soumi
3   a     summi
4   b  samiksha
  key  Marks
0   a     80
1   b    100
  key      name  Marks
0   a     ankit     80
1   a     summi     80
2   b      kiio    100
3   b  samiksha    100
  key      name  Marks
0   a     ankit     80
1   a     summi     80
2   b      kiio    100
3   b  samiksha    100


(15)

If the column names are different in each object, you can specify them separately

  lkey  data1 rkey  data2
0    b      0    b      1
1    b      1    b      1
2    b      6    b      1
3    a      2    a      0
4    a      4    a      0
5    a      5    a      0

(16)

You may notice that the 'c' and 'd' values and associated data are missing from the result. By default merge does an 'inner' join; the keys in the result are 
the intersection, or the common set found in both tables. Other possible options are 'left', 'right', and 'outer'. 
The outer join takes the union of the keys, combining the effect of applying both left and right joins:

print(pd.merge(df1, df2, how='outer'))

--

  key      name  Marks
0   a     ankit   80.0
1   a     summi   80.0
2   b      kiio  100.0
3   b  samiksha  100.0
4   c     soumi    NaN

(17)

To merge with multiple keys, pass a list of column names

left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'],'key2': ['one', 'two', 'one'],'lval': [1, 2, 3]})
right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],'key2': ['one', 'one', 'one', 'two'],'rval': [4, 5, 6, 7]})
print(pd.merge(left, right, on=['key1', 'key2'], how='outer'))

--

  key1 key2  lval  rval
0  foo  one   1.0   4.0
1  foo  one   1.0   5.0
2  foo  two   2.0   NaN
3  bar  one   3.0   6.0
4  bar  two   NaN   7.0

(18)

left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'],'key2': ['one', 'two', 'one'],'lval': [1, 2, 3]})
right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],'key2': ['one', 'one', 'one', 'two'],'rval': [4, 5, 6, 7]})
print(left)
print(right)
print(pd.merge(left, right, on='key1', suffixes=('_left', '_right')))

--

  key1 key2  lval
0  foo  one     1
1  foo  two     2
2  bar  one     3
  key1 key2  rval
0  foo  one     4
1  foo  one     5
2  bar  one     6
3  bar  two     7
  key1 key2_left  lval key2_right  rval
0  foo       one     1        one     4
1  foo       one     1        one     5
2  foo       two     2        one     4
3  foo       two     2        one     5
4  bar       one     3        one     6
5  bar       one     3        two     7

(19)

In some cases, the merge key(s) in a DataFrame will be found in its index. In this case, you can pass 
left_index=True or right_index=True (or both) to indicate that the index should be used as the merge key:

left1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],'value': range(6)})
right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])
print(left1)
print(right1)
print(pd.merge(left1, right1, left_on='key', right_index=True, how='outer'))

--

  key  value
0   a      0
1   b      1
2   a      2
3   a      3
4   b      4
5   c      5
   group_val
a        3.5
b        7.0
  key  value  group_val
0   a      0        3.5
2   a      2        3.5
3   a      3        3.5
1   b      1        7.0
4   b      4        7.0
5   c      5        NaN

(20)

left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],index=['a', 'c', 'e'],columns=['Ohio', 'Nevada'])
right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],index=['b', 'c', 'd', 'e'],columns=['Missouri', 'Alabama'])
print(left2)
print(right2)
print(pd.merge(left2, right2, how='outer', left_index=True, right_index=True))

--

   Ohio  Nevada
a   1.0     2.0
c   3.0     4.0
e   5.0     6.0
   Missouri  Alabama
b       7.0      8.0
c       9.0     10.0
d      11.0     12.0
e      13.0     14.0
   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0

(21)

DataFrame has a convenient join instance for merging by index. It can also be used to combine together 
many DataFrame objects having the same or similar indexes but non-overlapping columns. In the prior example, we could have written:

print(left2.join(right2, how='outer'))

--

   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0

(22)

print(left1.join(right1, on='key'))

--

  key  value  group_val
0   a      0        3.5
1   b      1        7.0
2   a      2        3.5
3   a      3        3.5
4   b      4        7.0
5   c      5        NaN

(23)

left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],index=['a', 'c', 'e'],columns=['Ohio', 'Nevada'])
right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],index=['b', 'c', 'd', 'e'],columns=['Missouri', 'Alabama'])
print(left2)
print(right2)
another = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],index=['a', 'c', 'e', 'f'],columns=['New York', 'Oregon'])
print(another)
print(left2.join([right2, another], how='outer'))

--

   Ohio  Nevada
a   1.0     2.0
c   3.0     4.0
e   5.0     6.0
   Missouri  Alabama
b       7.0      8.0
c       9.0     10.0
d      11.0     12.0
e      13.0     14.0
   New York  Oregon
a       7.0     8.0
c       9.0    10.0
e      11.0    12.0
f      16.0    17.0
   Ohio  Nevada  Missouri  Alabama  New York  Oregon
a   1.0     2.0       NaN      NaN       7.0     8.0
c   3.0     4.0       9.0     10.0       9.0    10.0
e   5.0     6.0      13.0     14.0      11.0    12.0
b   NaN     NaN       7.0      8.0       NaN     NaN
d   NaN     NaN      11.0     12.0       NaN     NaN
f   NaN     NaN       NaN      NaN      16.0    17.0

(24)

Another kind of data combination operation is referred to interchangeably as concatenation, binding, or stacking. 
NumPy’s concatenate function can do this with NumPy arrays

arr = np.arange(12).reshape((3, 4))
print(np.concatenate([arr, arr], axis=1))

--

[[ 0  1  2  3  0  1  2  3]
 [ 4  5  6  7  4  5  6  7]
 [ 8  9 10 11  8  9 10 11]]

(25)

s1 = pd.Series([0, 1], index=['a', 'b'])
s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])
s3 = pd.Series([5, 6], index=['f', 'g'])
print(pd.concat([s1, s2, s3]))

--

a    0
b    1
c    2
d    3
e    4
f    5
g    6
dtype: int64

(26)

print(pd.concat([s1, s2, s3], axis=1))

--

     0    1    2
a  0.0  NaN  NaN
b  1.0  NaN  NaN
c  NaN  2.0  NaN
d  NaN  3.0  NaN
e  NaN  4.0  NaN
f  NaN  NaN  5.0
g  NaN  NaN  6.0

(27)

s1 = pd.Series([0, 1], index=['a', 'b'])
s4 = pd.concat([s1, s3])
print(s1)
print(s4)
print(pd.concat([s1, s4], axis=1, join='inner'))

--

a    0
b    1
dtype: int64
a    0
b    1
f    5
g    6
dtype: int64
   0  1
a  0  0
b  1  1

(28)

Suppose instead you wanted to create a hierarchical index on the concatenation axis. To do this, use the keys argument:

result = pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])
print(result)
print(result.unstack())
print(pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three']))

--

one    a    0
       b    1
two    a    0
       b    1
three  f    5
       g    6
dtype: int64
         a    b    f    g
one    0.0  1.0  NaN  NaN
two    0.0  1.0  NaN  NaN
three  NaN  NaN  5.0  6.0
   one  two  three
a  0.0  NaN    NaN
b  1.0  NaN    NaN
c  NaN  2.0    NaN
d  NaN  3.0    NaN
e  NaN  4.0    NaN
f  NaN  NaN    5.0
g  NaN  NaN    6.0

(29)

df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'],columns=['one', 'two'])
df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'],columns=['three', 'four'])
print(df1)
print(df2)
print(pd.concat([df1, df2], axis=1, keys=['level1', 'level2']))

--

   one  two
a    0    1
b    2    3
c    4    5
   three  four
a      5     6
c      7     8
  level1     level2     
     one two  three four
a      0   1    5.0  6.0
b      2   3    NaN  NaN
c      4   5    7.0  8.0

(30)

print(pd.concat({'level1': df1, 'level2': df2}, axis=1))

--

  level1     level2     
     one two  three four
a      0   1    5.0  6.0
b      2   3    NaN  NaN
c      4   5    7.0  8.0

(31)

print(pd.concat([df1, df2], axis=1, keys=['level1', 'level2'],names=['upper', 'lower']))

--

upper level1     level2     
lower    one two  three four
a          0   1    5.0  6.0
b          2   3    NaN  NaN
c          4   5    7.0  8.0

(32)

Hierarchical indexing provides a consistent way to rearrange data in a DataFrame. There are two primary actions:

stack: This “rotates” or pivots from the columns in the data to the rows

unstack: This pivots from the rows into the columns

(33)

Using the stack method on this data pivots the columns into the rows, producing a Series:

result = data.stack()
print(result)

--

state     number
Ohio      one       0
          two       1
          three     2
Colorado  one       3
          two       4
          three     5
dtype: int32

(34)

By default the innermost level is unstacked (same with stack). You can unstack a different level by passing a level number or name:

print(result.unstack())

--

number    one  two  three
state                    
Ohio        0    1      2
Colorado    3    4      5

print(result.unstack(0))

--

state   Ohio  Colorado
number                
one        0         3
two        1         4
three      2         5

(35)

When you unstack in a DataFrame, the level unstacked becomes the lowest level in the result:

df = pd.DataFrame({'left': result, 'right': result + 5},columns=pd.Index(['left', 'right'], name='side'))
print(df)
print(df.unstack('state'))
print(df.unstack('state').stack('side'))

--

side             left  right
state    number             
Ohio     one        0      5
         two        1      6
         three      2      7
Colorado one        3      8
         two        4      9
         three      5     10
side   left          right         
state  Ohio Colorado  Ohio Colorado
number                             
one       0        3     5        8
two       1        4     6        9
three     2        5     7       10
state         Colorado  Ohio
number side                 
one    left          3     0
       right         8     5
two    left          4     1
       right         9     6
three  left          5     2
       right        10     7

(36)

A common way to store multiple time series in databases and CSV is in so-called long or stacked format. 
Let’s load some example data and do a small amount of time series wrangling and other data cleaning:

data = pd.read_csv('macrodata.csv')
print(data.head(2))

--

     year  quarter   realgdp  realcons  realinv  realgovt  realdpi    cpi  \
0  1959.0      1.0  2710.349    1707.4  286.898   470.045   1886.9  28.98   
1  1959.0      2.0  2778.801    1733.7  310.859   481.301   1919.7  29.15   

      m1  tbilrate  unemp      pop  infl  realint  
0  139.7      2.82    5.8  177.146  0.00     0.00  
1  141.7      3.08    5.1  177.830  2.34     0.74 


periods = pd.PeriodIndex(year=data.year, quarter=data.quarter,name='date')
columns = pd.Index(['realgdp', 'infl', 'unemp'], name='item')
data = data.reindex(columns=columns)
data.index = periods.to_timestamp('D', 'end')
ldata = data.stack().reset_index().rename(columns={0: 'value'})

--

ldata[:10]

				date	item	value
0	1959-03-31 23:59:59.999999999	realgdp	2710.349
1	1959-03-31 23:59:59.999999999	infl	0.000
2	1959-03-31 23:59:59.999999999	unemp	5.800
3	1959-06-30 23:59:59.999999999	realgdp	2778.801
4	1959-06-30 23:59:59.999999999	infl	2.340
5	1959-06-30 23:59:59.999999999	unemp	5.100
6	1959-09-30 23:59:59.999999999	realgdp	2775.488
7	1959-09-30 23:59:59.999999999	infl	2.740
8	1959-09-30 23:59:59.999999999	unemp	5.300
9	1959-12-31 23:59:59.999999999	realgdp	2785.204

This is the so-called long format for multiple time series, or other observational data with two or more keys (here, our keys are date and item). 
Each row in the table represents a single observation.

(37)

pivoted = ldata.pivot('date', 'item', 'value')
pivoted

--

			item	infl	realgdp	       unemp
date			
1959-03-31 23:59:59.999999999	0.00	2710.349	5.8
1959-06-30 23:59:59.999999999	2.34	2778.801	5.1
1959-09-30 23:59:59.999999999	2.74	2775.488	5.3
1959-12-31 23:59:59.999999999	0.27	2785.204	5.6
1960-03-31 23:59:59.999999999	2.31	2847.699	5.2
...	...	...	...
2008-09-30 23:59:59.999999999	-3.16	13324.600	6.0
2008-12-31 23:59:59.999999999	-8.79	13141.920	6.9
2009-03-31 23:59:59.999999999	0.94	12925.410	8.1
2009-06-30 23:59:59.999999999	3.37	12901.504	9.2
2009-09-30 23:59:59.999999999	3.56	12990.341	9.6

(38)

By omitting the last argument, you obtain a DataFrame with hierarchical columns:

pivoted = ldata.pivot('date', 'item')
print(pivoted[:5])

--

                              value                
item                           infl   realgdp unemp
date                                               
1959-03-31 23:59:59.999999999  0.00  2710.349   5.8
1959-06-30 23:59:59.999999999  2.34  2778.801   5.1
1959-09-30 23:59:59.999999999  2.74  2775.488   5.3
1959-12-31 23:59:59.999999999  0.27  2785.204   5.6
1960-03-31 23:59:59.999999999  2.31  2847.699   5.2

(39)

Note that pivot is equivalent to creating a hierarchical index using set_index followed by a call to unstack:

unstacked = ldata.set_index(['date', 'item']).unstack('item')
print(unstacked)

--

                              value                 
item                           infl    realgdp unemp
date                                                
1959-03-31 23:59:59.999999999  0.00   2710.349   5.8
1959-06-30 23:59:59.999999999  2.34   2778.801   5.1
1959-09-30 23:59:59.999999999  2.74   2775.488   5.3
1959-12-31 23:59:59.999999999  0.27   2785.204   5.6
1960-03-31 23:59:59.999999999  2.31   2847.699   5.2
...                             ...        ...   ...
2008-09-30 23:59:59.999999999 -3.16  13324.600   6.0
2008-12-31 23:59:59.999999999 -8.79  13141.920   6.9
2009-03-31 23:59:59.999999999  0.94  12925.410   8.1
2009-06-30 23:59:59.999999999  3.37  12901.504   9.2
2009-09-30 23:59:59.999999999  3.56  12990.341   9.6

[203 rows x 3 columns]

(40)

An inverse operation to pivot for DataFrames is pandas.melt. Rather than transforming one column into many in a new DataFrame, 
it merges multiple columns into one, producing a DataFrame that is longer than the input. Let’s look at an example:

The 'key' column may be a group indicator, and the other columns are data values. When using pandas.melt, we must indicate which columns (if any) are group indicators. 
Let’s use 'key' as the only group indicator here:

melted = pd.melt(df, ['key'])
print(melted)

--

   key variable  value
0  foo        A      1
1  bar        A      2
2  baz        A      3
3  foo        B      4
4  bar        B      5
5  baz        B      6
6  foo        C      7
7  bar        C      8
8  baz        C      9

(41)

Using pivot, we can reshape back to the original layout:

reshaped=melted.pivot('key','variable','value')
print(reshaped)

--

variable  A  B  C
key              
bar       2  5  8
baz       3  6  9
foo       1  4  7

(42)

Since the result of pivot creates an index from the column used as the row labels, we may want to use reset_index to move the data back into a column:

print(reshaped.reset_index())

--

variable  key  A  B  C
0         bar  2  5  8
1         baz  3  6  9
2         foo  1  4  7

(43)

You can also specify a subset of columns to use as value columns:

print(pd.melt(df, id_vars=['key'], value_vars=['A', 'B']))

--

   key variable  value
0  foo        A      1
1  bar        A      2
2  baz        A      3
3  foo        B      4
4  bar        B      5
5  baz        B      6

(44)

pd.melt(df, value_vars=['key', 'A', 'B'])

--


       variable value
0	key	foo
1	key	bar
2	key	baz
3	A	1
4	A	2
5	A	3
6	B	4
7	B	5
8	B	6

--------------------------------------------------------------------------------------------------------------------------------------------------------------

(45)

Plotting may be a part of the exploratory process—for example, to help identify outliers or needed data transformations.

matplotlib is a desktop plotting package designed for creating (mostly two dimensional) publication-quality plots. 
The project was started by John Hunter in 2002 to enable a MATLAB-like plotting interface in Python.

%matplotlib notebook
import numpy as np
import matplotlib.pyplot as plt
data=np.arange(10)
plt.plot(data) #x=[0,1,2,...,9] and y=[0,1,2,...,9]

(46)

Plots in matplotlib reside within a Figure object. You can create a new figure with plt.figure.

fig=plt.figure()

plt.figure has a number of options; notably, figsize will guarantee the figure has a certain size and aspect ratio if saved to disk.

(47)

You have to create one or more subplots using add_subplot:

One nuance of using Jupyter notebooks is that plots are reset after each cell is evaluated, 
so for more complex plots you must put all of the plotting commands in a single notebook cell.

When you issue a plotting command like plt.plot([1.5, 3.5, -2, 1.6]), matplotlib draws on the last figure and subplot used (creating one if necessary),
thus hiding the figure and subplot creation.

fig=plt.figure()
ax1=fig.add_subplot(2,2,1)
ax2=fig.add_subplot(2,2,2)
ax3=fig.add_subplot(2,2,3)
ax4=fig.add_subplot(2,2,4)
plt.plot([1,1.4,3.1,-1,2,-1])
plt.plot([1,-1,1,-1,1,-1,1])
plt.plot(np.random.randn(50).cumsum(), 'k--')

(48)

The 'k--' is a style option instructing matplotlib to plot a black dashed line. The objects returned by fig.add_subplot here are AxesSubplot objects, 
on which you can directly plot on the other empty subplots by calling each one’s instance method

fig=plt.figure()
ax1=fig.add_subplot(2,2,1)
ax2=fig.add_subplot(2,2,2)
ax3=fig.add_subplot(2,2,3)
ax4=fig.add_subplot(2,2,4)
plt.plot([1,1.4,3.1,-1,2,-1])
plt.plot([1,-1,1,-1,1,-1,1])
ax1.plot(np.random.randn(50).cumsum(), 'k--')
ax2.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30))
ax3.hist([1,2,1,1,3,3,3,3,2,6,7], bins=10, color='k', alpha=0.3)

(49)

Creating a figure with a grid of subplots is a very common task, so matplotlib includes a convenience method, plt.subplots, 
that creates a new figure and returns a NumPy array containing the created subplot objects.

This is very useful, as the axes array can be easily indexed like a two-dimensional array; for example, axes[0, 1]. You can also indicate that subplots 
should have the same x- or y-axis using sharex and sharey, respectively. 
This is especially useful when you’re comparing data on the same scale; otherwise, matplotlib autoscales plot limits independently. 

Table 9-1. pyplot.subplots options
Argument --> Description

nrows --> Number of rows of subplots

ncols --> Number of columns of subplots

sharex --> All subplots should use the same x-axis ticks (adjusting the xlim will affect all subplots)

sharey --> All subplots should use the same y-axis ticks (adjusting the ylim will affect all subplots)

subplot_kw --> Dict of keywords passed to add_subplot call used to create each subplot

**fig_kw --> Additional keywords to subplots are used when creating the figure, such as plt.subplots(2, 2, figsize=(8, 6))

(50)

By default matplotlib leaves a certain amount of padding around the outside of the subplots and spacing between subplots. 
This spacing is all specified relative to the height and width of the plot, so that if you resize the plot either programmatically or manually using the GUI window, 
the plot will dynamically adjust itself. You can change the spacing using the subplots_adjust method on Figure objects, also available as a top-level function:

# subplots_adjust(left=None, bottom=None, right=None, top=None,
#  wspace=None, hspace=None)


(51)

wspace and hspace controls the percent of the figure width and figure height, respectively, to use as spacing between subplots.

fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)
for i in range(2):
    for j in range(2):
        axes[i, j].hist(np.random.randn(500), bins=50, color='k', alpha=0.5)
plt.subplots_adjust(wspace=0, hspace=0)

(52)

Matplotlib’s main plot function accepts arrays of x and y coordinates and optionally a string abbreviation indicating color and line style. 
For example, to plot x versus y with green dashes, you would execute:

# ax.plot(x, y, 'g--')

(53)

This way of specifying both color and line style in a string is provided as a convenience; in practice if you were creating plots programmatically 
you might prefer not to have to munge strings together to create plots with the desired style. 
The same plot could also have been expressed more explicitly as:

# ax.plot(x, y, linestyle='--', color='g')

(54)

There are a number of color abbreviations provided for commonly used colors, but you can use any color on the spectrum by specifying its hex code (e.g., '#CECECE'). 
You can see the full set of line styles by looking at the docstring for plot (use plot? in IPython or Jupyter).

plt?

(55)

Line plots can additionally have markers to highlight the actual data points. Since matplotlib creates a continuous line plot, interpolating between points, 
it can occasionally be unclear where the points lie. The marker can be part of the style string, which must have color followed by marker type and line style

fig=plt.figure()
plt.plot(np.random.randn(30).cumsum(), color='green', linestyle='dashed', marker='o')

(56)

For line plots, you will notice that subsequent points are linearly interpolated by default. This can be altered with the drawstyle option

data = np.random.randn(30).cumsum()
fig=plt.figure()
plt.plot(data, 'k--', label='Default')
plt.plot(data, 'k-', drawstyle='steps-post', label='steps-post')
plt.legend(loc='best')

You must call plt.legend (or ax.legend, if you have a reference to the axes) to create the legend, whether or not you passed the label options when plotting the data.

(57)

For most kinds of plot decorations, there are two main ways to do things: using the procedural pyplot interface (i.e., matplotlib.pyplot) and 
the more object-oriented native matplotlib API.

The pyplot interface, designed for interactive use, consists of methods like xlim, xticks, and xticklabels. These control the plot range, tick locations, and 
tick labels, respectively. They can be used in two ways

• Called with no arguments returns the current parameter value (e.g., plt.xlim() returns the current x-axis plotting range)

• Called with parameters sets the parameter value (e.g., plt.xlim([0, 10]), sets the x-axis range to 0 to 10)

All such methods act on the active or most recently created AxesSubplot. Each of them corresponds to two methods on the subplot object itself; 
in the case of xlim these are ax.get_xlim and ax.set_xlim. 
I prefer to use the subplot instance methods myself in the interest of being explicit (and especially when working with multiple subplots), 
but you can certainly use whichever you find more convenient.

(58)

Setting the title, axis labels, ticks, and ticklabels:

To change the x-axis ticks, it’s easiest to use set_xticks and set_xticklabels. The former instructs matplotlib where to place the ticks along the data range; 
by default these locations will also be the labels. But we can set any other values as the labels using set_xticklabels:

The rotation option sets the x tick labels at a 30-degree rotation. Lastly, set_xlabel gives a name to the x-axis and set_title the subplot title 

fig=plt.figure()
ax=fig.add_subplot(1,1,1)
ax.plot(np.random.randn(1000).cumsum())
ticks =ax.set_xticks([0, 250, 500, 750, 1000])
labels = ax.set_xticklabels(['one', 'two', 'three', 'four', 'five'],rotation=30, fontsize='small')
ax.set_title('My first matplotlib plot')
ax.set_xlabel('Stages')
ax.set_ylabel('Cumulative Sum')

(59)

from numpy.random import randn
fig = plt.figure(); ax = fig.add_subplot(1, 1, 1)
ax.plot(randn(1000).cumsum(), 'k', label='one')
ax.plot(randn(1000).cumsum(), 'k--', label='two')
ax.plot(randn(1000).cumsum(), 'k.', label='three')
ax.legend(loc='best')

(60)

In addition to the standard plot types, you may wish to draw your own plot annotations, which could consist of text, arrows, or other shapes. 
You can add annotations and text using the text, arrow, and annotate functions. text draws text at given coordinates (x, y) on the plot with optional custom styling


# ax.text(x, y, 'Hello world!',family='monospace', fontsize=10)

(61)

import pandas as pd
from datetime import datetime
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
data = pd.read_csv('spx.csv', index_col=0, parse_dates=True)
spx = data['SPX']
spx.plot(ax=ax, style='k-')
crisis_data = [
 (datetime(2007, 10, 11), 'Peak of bull market'),
 (datetime(2008, 3, 12), 'Bear Stearns Fails'),
 (datetime(2008, 9, 15), 'Lehman Bankruptcy')
]
for date, label in crisis_data:
    ax.annotate(label, xy=(date, spx.asof(date) + 75),xytext=(date, spx.asof(date) + 225),arrowprops=dict(facecolor='black', headwidth=4, width=2,headlength=4),
    horizontalalignment='left', verticalalignment='top')
# Zoom in on 2007-2010
ax.set_xlim(['1/1/2007', '1/1/2011'])
ax.set_ylim([600, 1800])
ax.set_title('Important dates in the 2008-2009 financial crisis')


There are a couple of important points to highlight in this plot: the ax.annotate method can draw labels at the indicated x and y coordinates. 
We use the set_xlim and set_ylim methods to manually set the start and end boundaries for the plot rather than using matplotlib’s default. 
Lastly, ax.set_title adds a main title to the plot.

Drawing shapes requires some more care. matplotlib has objects that represent many common shapes, referred to as patches. 
Some of these, like Rectangle and Circle, are found in matplotlib.pyplot, but the full set is located in matplotlib.patches.

To add a shape to a plot, you create the patch object shp and add it to a subplot by calling ax.add_patch(shp) 

(62)

fig=plt.figure()
ax=fig.add_subplot(1,1,1)
rect=plt.Rectangle((0.2,0.75),0.4,0.15,color='k',alpha=0.3)
circ=plt.Circle((0.7,0.2),0.15,color='b',alpha=0.3)
poly=plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]],color='g', alpha=0.5)
ax.add_patch(rect)
ax.add_patch(circ)
ax.add_patch(poly)

(63)

You can save the active figure to file using plt.savefig. This method is equivalent to the figure object’s savefig instance method.

The file type is inferred from the file extension. So if you used .pdf instead, you would get a PDF. There are a couple of important options that 
I use frequently for publishing graphics: dpi, which controls the dots-per-inch resolution, and bbox_inches, which can trim the whitespace around the actual figure. 
To get the same plot as a PNG with minimal whitespace around the plot and at 400 DPI, you would do:

plt.savefig('shapes.png',dpi=400,bbox_inches='tight')
plt.savefig('shapes.pdf',dpi=400,bbox_inches='tight')

(64)

savefig doesn’t have to write to disk; it can also write to any file-like object, such as a BytesIO:

from io import BytesIO
buffer = BytesIO()
plt.savefig(buffer)
plot_data = buffer.getvalue()

(65)

matplotlib Configuration:

The first argument to rc is the component you wish to customize, such as 'figure', 'axes', 'xtick', 'ytick', 'grid', 'legend', or many others. 
After that can follow a sequence of keyword arguments indicating the new parameters. An easy way to write down the options in your program is as a dict:

font_options = {'family' : 'monospace',
 'weight' : 'bold'}
plt.rc('font', **font_options)


For more extensive customization and to see a list of all the options, matplotlib comes with a configuration file matplotlibrc in the matplotlib/mpl-data directory. 
If you customize this file and place it in your home directory titled .matplotlibrc, it will be loaded each time you use matplotlib

(66)

Plotting with pandas and seaborn:

matplotlib can be a fairly low-level tool. You assemble a plot from its base components: the data display (i.e., the type of plot: line, bar, box, scatter, contour, etc.), 
leg‐ end, title, tick labels, and other annotations.

In pandas we may have multiple columns of data, along with row and column labels. pandas itself has built-in methods that simplify creating visualizations from DataFrame and Series objects. 
Another library is seaborn, a statistical graphics library created by Michael Waskom. Seaborn simplifies creating many common visualization types.

Importing seaborn modifies the default matplotlib color schemes and plot styles to improve readability and aesthetics. Even if you do not use the seaborn API, 
you may prefer to import seaborn as a simple way to improve the visual aesthetics of general matplotlib plots

(67)

Line Plots:

Series and DataFrame each have a plot attribute for making some basic plot types

fig = plt.figure()
s = pd.Series(np.random.randn(10).cumsum(), index=np.arange(0, 100, 10))
s.plot()

The Series object’s index is passed to matplotlib for plotting on the x-axis, though you can disable this by passing use_index=False. The x-axis ticks and limits 
can be adjusted with the xticks and xlim options, and y-axis respectively with yticks and ylim.

The Series object’s index is passed to matplotlib for plotting on the x-axis, though you can disable this by passing use_index=False. The x-axis ticks and 
limits can be adjusted with the xticks and xlim options, and y-axis respectively with yticks and ylim.

DataFrame’s plot method plots each of its columns as a different line on the same subplot, creating a legend automatically

df = pd.DataFrame(np.random.randn(10, 4).cumsum(0),columns=['A', 'B', 'C', 'D'],index=np.arange(0, 100, 10))
df.plot()

The plot attribute contains a “family” of methods for different plot types. For example, df.plot() is equivalent to df.plot.line().

Additional keyword arguments to plot are passed through to the respective matplotlib plotting function, so you can further 
customize these plots by learning more about the matplotlib API.

(68)

Table 9-3. Series.plot method arguments
Argument --> Description

label --> Label for plot legend

ax --> matplotlib subplot object to plot on; if nothing passed, uses active matplotlib subplot

style --> Style string, like 'ko--', to be passed to matplotlib

alpha --> The plot fill opacity (from 0 to 1)

kind --> Can be 'area', 'bar', 'barh', 'density', 'hist', 'kde', 'line', 'pie'

logy --> Use logarithmic scaling on the y-axis

use_index --> Use the object index for tick labels

rot --> Rotation of tick labels (0 through 360)

xticks --> Values to use for x-axis ticks

yticks --> Values to use for y-axis ticks

xlim --> x-axis limits (e.g., [0, 10])

ylim --> y-axis limits

grid --> Display axis grid (on by default)

(69)

Table 9-4. DataFrame-specific plot arguments
Argument --> Description

subplots --> Plot each DataFrame column in a separate subplot

sharex --> If subplots=True, share the same x-axis, linking ticks and limits

sharey --> If subplots=True, share the same y-axis

figsize --> Size of figure to create as tuple

title --> Plot title as string

legend --> Add a subplot legend (True by default)

sort_columns --> Plot columns in alphabetical order; by defaul it uses existing column order

(70)

Bar Plots:

The plot.bar() and plot.barh() make vertical and horizontal bar plots, respectively. 
In this case, the Series or DataFrame index will be used as the x (bar) or y (barh) ticks

fig, axes = plt.subplots(2, 1)
data = pd.Series(np.random.rand(16), index=list('abcdefghijklmnop'))
data.plot.bar(ax=axes[0], color='k', alpha=0.7)
data.plot.barh(ax=axes[1], color='k', alpha=0.7)

The options color='k' and alpha=0.7 set the color of the plots to black and use partial transparency on the filling.

(71)

With a DataFrame, bar plots group the values in each row together in a group in bars, side by side, for each value.

df = pd.DataFrame(np.random.rand(6, 4),index=['one', 'two', 'three', 'four', 'five', 'six'],columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))
df.plot.bar()

Note that the name “Genus” on the DataFrame’s columns is used to title the legend.

(72)

We create stacked bar plots from a DataFrame by passing stacked=True, resulting in the value in each row being stacked together.

df.plot.barh(stacked=True, alpha=0.5)

A useful recipe for bar plots is to visualize a Series’s value frequency using value_counts: s.value_counts().plot.bar().

(73)

Returning to the tipping dataset used earlier in the book, suppose we wanted to make a stacked bar plot showing the percentage of data points for each party size on each day. 
I load the data using read_csv and make a cross-tabulation by day and party size:

tips = pd.read_csv('tips.csv')
party_counts = pd.crosstab(tips['day'], tips['size'])
print(party_counts)

--

size  1   2   3   4  5  6
day                      
Fri   1  16   1   1  0  0
Sat   2  53  18  13  1  0
Sun   0  39  15  18  3  1
Thur  1  48   4   5  1  3

party_counts = party_counts.loc[:, 2:5]
party_pcts = party_counts.div(party_counts.sum(1), axis=0)
print(party_pcts)

--

size         2         3         4         5
day                                         
Fri   0.888889  0.055556  0.055556  0.000000
Sat   0.623529  0.211765  0.152941  0.011765
Sun   0.520000  0.200000  0.240000  0.040000
Thur  0.827586  0.068966  0.086207  0.017241

party_pcts.plot.bar()

So you can see that party sizes appear to increase on the weekend in this dataset. 
With data that requires aggregation or summarization before making a plot, using the seaborn package can make things much simpler. 
Let’s look now at the tipping percentage by day with seaborn (see Figure 9-19 for the resulting plot):

import seaborn as sns
tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip'])
print(tips.head())

--

   total_bill   tip     sex smoker  day    time  size   tip_pct
0       16.99  1.01  Female     No  Sun  Dinner     2  0.063204
1       10.34  1.66    Male     No  Sun  Dinner     3  0.191244
2       21.01  3.50    Male     No  Sun  Dinner     3  0.199886
3       23.68  3.31    Male     No  Sun  Dinner     2  0.162494
4       24.59  3.61  Female     No  Sun  Dinner     4  0.172069


fig=plt.figure()
sns.barplot(x='tip_pct', y='day', data=tips, orient='h')

(74)

Plotting functions in seaborn take a data argument, which can be a pandas DataFrame. The other arguments refer to column names. 
Because there are multiple observations for each value in the day, the bars are the average value of tip_pct. 
The black lines drawn on the bars represent the 95% confidence interval (this can be con‐ figured through optional arguments).


seaborn.barplot has a hue option that enables us to split by an additional categorical value

fig=plt.figure()
sns.barplot(x='tip_pct', y='day', hue='time', data=tips, orient='h')

(75)

Notice that seaborn has automatically changed the aesthetics of plots: the default color palette, plot background, and grid line colors. 
You can switch between different plot appearances using seaborn.set:

sns.set(style="whitegrid")

(76)

Histograms and Density Plots:

A histogram is a kind of bar plot that gives a discretized display of value frequency. The data points are split into discrete, evenly spaced bins, and 
the number of data points in each bin is plotted. 
Using the tipping data from before, we can make a histogram of tip percentages of the total bill using the plot.hist method on the Series

fig=plt.figure()
tips['tip_pct'].plot.hist(bins=50)

(77)

A related plot type is a density plot, which is formed by computing an estimate of a continuous probability distribution that might have generated the observed data. 
The usual procedure is to approximate this distribution as a mixture of “kernels”—that is, simpler distributions like the normal distribution. 
Thus, density plots are also known as kernel density estimate (KDE) plots. Using plot.kde makes a density plot using the conventional mixture-of-normals estimate

fig=plt.figure()
tips['tip_pct'].plot.density()

(78)

Seaborn makes histograms and density plots even easier through its distplot method, which can plot both a histogram and a continuous density estimate simultaneously. 
As an example, consider a bimodal distribution consisting of draws from two different standard normal distributions 

fig=plt.figure()
comp1 = np.random.normal(0, 1, size=200)
comp2 = np.random.normal(10, 2, size=200)
values = pd.Series(np.concatenate([comp1, comp2]))
sns.distplot(values, bins=100, color='k')

(79)

Scatter or Point Plots:

Point plots or scatter plots can be a useful way of examining the relationship between two one-dimensional data series.

macro = pd.read_csv('macrodata.csv')
data = macro[['cpi', 'm1', 'tbilrate', 'unemp']]
trans_data = np.log(data).diff().dropna()
print(trans_data[-5:])

--

          cpi        m1  tbilrate     unemp
198 -0.007904  0.045361 -0.396881  0.105361
199 -0.021979  0.066753 -2.277267  0.139762
200  0.002340  0.010286  0.606136  0.160343
201  0.008419  0.037461 -0.200671  0.127339
202  0.008894  0.012202 -0.405465  0.042560

We can then use seaborn’s regplot method, which makes a scatter plot and fits a linear regression line:

fig=plt.figure()
sns.regplot(x='m1',y='unemp', data=trans_data)
plt.title('Changes in log %s versus log %s' % ('m1', 'unemp'))

(80)

In exploratory data analysis it’s helpful to be able to look at all the scatter plots among a group of variables; this is known as a pairs plot or scatter plot matrix. 
Making such a plot from scratch is a bit of work, 
so seaborn has a convenient pairplot function, which supports placing histograms or density estimates of each variable along the diagonal

sns.pairplot(trans_data, diag_kind='kde', plot_kws={'alpha': 0.2})

You may notice the plot_kws argument. This enables us to pass down configuration options to the individual plotting calls on the off-diagonal elements. 
Check out the seaborn.pairplot docstring for more granular configuration options

(81)

Facet Grids and Categorical Data:

What about datasets where we have additional grouping dimensions? One way to visualize data with many categorical variables is to use a facet grid. 
Seaborn has a useful built-in function catplot that simplifies making many kinds of faceted plots

sns.catplot(x='day', y='tip_pct', hue='time', col='smoker',kind='bar', data=tips[tips.tip_pct < 1])

Instead of grouping by 'time' by different bar colors within a facet, we can also expand the facet grid by adding one row per time value

sns.catplot(x='day', y='tip_pct', row='time',col='smoker',kind='bar', data=tips[tips.tip_pct < 1])

catplot supports other plot types that may be useful depending on what you are trying to display. 
For example, box plots (which show the median, quartiles, and outliers) can be an effective visualization type

sns.catplot(x='tip_pct', y='day', kind='box',data=tips[tips.tip_pct < 0.5])


(82)

With tools like Bokeh and Plotly, it’s now possible to specify dynamic, interactive graphics in Python that are destined for a web browser.

For creating static graphics for print or web, I recommend defaulting to matplotlib and add-on libraries like pandas and seaborn for your needs.